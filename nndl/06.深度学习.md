# 深度学习

我们已经了解了深度神经⽹络通常⽐浅层神经⽹络更加难以训练，但是为了获得比浅层网络更加强大的能力，我们需要训练深度网络，本章主要讨论可以⽤来训练深度神经⽹络的技术，并在实战中应⽤它们。

本章是一个大章节，主要围绕的是从简单的浅层网络到卷积神经网络来慢慢构建强大的网络，从而解决`MNIST`手写字识别的问题。

在这个过程中，我们需要研究的相关技术有：卷积、池化、使用GPU来更好地训练、训练数据的算法性拓展、Dropout、网络的综合使用等。

## 介绍卷积网络

在第一章**识别手写字**中，我们就利用全连接神经网络基于`MNIST`训练集构建了一个可以识别手写字的深度学习模型。

![image-20210112220944373](https://gitee.com/howie6879/oss/raw/master/uPic/image-20210112220944373.png)

让我们基于上面的网络结构思考下面几个问题：

- 参数过多：对于手写字，第一层的输入图像大小是$28*28=784$个，因此第一个隐藏层的每个神经元到输入层都有784个权重参数，大家可以基于此计算一下，五层的全连接神经网络，参数将极其庞大导致训练效率不高并且容易出现过拟合；
- 局表示不变性特征：目前的网络并没有考虑图像的空间结构，它在完全相同的基础上去对待相距很远和彼此接近的输⼊像素；自然图像中的物体都具有局部不变性特征，比如尺 度缩放、平移、旋转等操作不影响其语义信息．而全连接前馈网络很难提取这些 局部不变性特征，一般需要进行数据增强来提高性能。

卷积神经网络（Convolutional Neural Network，CNN 或 ConvNet）是一类特殊的人工神经网络，也是第一章提到的多层感知器（MLP）的变种。

我们可以从生物学角度出发，来看看卷积神经网络有哪些基本特征。我们知道视觉皮层的细胞存在 一个复杂的构造，这些细胞对视觉输入空间的子区域非常敏感，我们称之为**感受野**。在全连接网络中我们会将所有的输入神经元都连接到下一个隐藏的神经元，但这次我们不这么干，我们选择一个$5*5$的区域进行局部区域的连接：

![image-20210112225008050](https://gitee.com/howie6879/oss/raw/master/uPic/image-20210112225008050.png)

这个输⼊图像的区域被称为隐藏神经元的**局部感受野**，然后在整个输⼊图像上交叉移动局部感受野，此时我们的$28*28=784$个输入，用$5*5$的局部感受野，此时第一个隐藏层就会有$24*24$个神经元：

![image-20210112225311394](https://gitee.com/howie6879/oss/raw/master/uPic/image-20210112225311394.png)



## 参考

- [Neural Networks and Deep Learning](http://neuralnetworksanddeeplearning.com/index.html)
- [Neural Networks and Deep Learning 中文版](https://github.com/zhanggyb/nndl)
- [神经网络与深度学习-邱锡鹏](https://nndl.github.io/)
- 

搞定收工，有兴趣欢迎关注我的公众号：

![img](https://raw.githubusercontent.com/howie6879/howie6879.github.io/img/pictures/howie_wechat.png)

